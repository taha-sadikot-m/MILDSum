"""Google Gemini LLM client for legal summarization."""

import logging
import asyncio
from typing import Dict, Any, List, Optional, Union
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

from ..config.settings import settings

logger = logging.getLogger(__name__)


class GeminiClient:
    """Client for interacting with Google's Gemini LLM."""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """Initialize Gemini client with configuration."""
        self.config = config or settings.gemini
        
        # Configure the API
        genai.configure(api_key=self.config.api_key)
        
        # Safety settings for legal content
        self.safety_settings = {
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
        
        # Initialize model
        self.model = genai.GenerativeModel(
            model_name=self.config.model_name,
            safety_settings=self.safety_settings
        )
        
        logger.info(f"Initialized Gemini client with model: {self.config.model_name}")
    
    async def generate_text(
        self, 
        prompt: str, 
        system_instruction: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> str:
        """Generate text using Gemini model."""
        try:
            # Use provided parameters or fall back to config defaults
            generation_config = genai.types.GenerationConfig(
                temperature=temperature or self.config.temperature,
                max_output_tokens=max_tokens or self.config.max_tokens,
                top_p=self.config.top_p,
                top_k=self.config.top_k,
            )
            
            # Add system instruction if provided
            if system_instruction:
                full_prompt = f"System: {system_instruction}\n\nUser: {prompt}"
            else:
                full_prompt = prompt
            
            # Generate content
            response = await asyncio.to_thread(
                self.model.generate_content,
                full_prompt,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )
            
            if response.candidates and response.candidates[0].content.parts:
                return response.candidates[0].content.parts[0].text
            else:
                logger.warning("No content generated by Gemini")
                return ""
                
        except Exception as e:
            logger.error(f"Error generating text with Gemini: {str(e)}")
            raise
    
    def generate_text_sync(
        self, 
        prompt: str, 
        system_instruction: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> str:
        """Synchronous text generation."""
        try:
            generation_config = genai.types.GenerationConfig(
                temperature=temperature or self.config.temperature,
                max_output_tokens=max_tokens or self.config.max_tokens,
                top_p=self.config.top_p,
                top_k=self.config.top_k,
            )
            
            if system_instruction:
                full_prompt = f"System: {system_instruction}\n\nUser: {prompt}"
            else:
                full_prompt = prompt
            
            response = self.model.generate_content(
                full_prompt,
                generation_config=generation_config,
                safety_settings=self.safety_settings
            )
            
            if response.candidates and response.candidates[0].content.parts:
                return response.candidates[0].content.parts[0].text
            else:
                logger.warning("No content generated by Gemini")
                return ""
                
        except Exception as e:
            logger.error(f"Error generating text with Gemini: {str(e)}")
            raise
    
    async def generate_structured_output(
        self, 
        prompt: str, 
        schema: Dict[str, Any],
        system_instruction: Optional[str] = None
    ) -> Dict[str, Any]:
        """Generate structured output following a specific schema."""
        schema_prompt = f"""
Please respond with a valid JSON object that follows this exact schema:
{schema}

{prompt}

Respond only with the JSON object, no additional text.
"""
        
        response_text = await self.generate_text(
            schema_prompt, 
            system_instruction,
            temperature=0.1  # Lower temperature for structured output
        )
        
        try:
            import json
            return json.loads(response_text.strip())
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON response: {response_text}")
            raise ValueError(f"Invalid JSON response from Gemini: {str(e)}")
    
    async def batch_generate(
        self, 
        prompts: List[str], 
        system_instruction: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> List[str]:
        """Generate text for multiple prompts in batch."""
        tasks = [
            self.generate_text(prompt, system_instruction, temperature, max_tokens)
            for prompt in prompts
        ]
        
        return await asyncio.gather(*tasks)
    
    def validate_api_key(self) -> bool:
        """Validate that the API key is working."""
        try:
            response = self.model.generate_content("Hello")
            return bool(response.candidates)
        except Exception as e:
            logger.error(f"API key validation failed: {str(e)}")
            return False